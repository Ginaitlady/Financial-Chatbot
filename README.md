# ğŸ’° Financial Chatbot

A **deep learning-powered chatbot** designed to answer financial questions using a **hybrid model architecture**.

---

## ğŸ“˜ Overview

This project implements a sophisticated chatbot that can handle two distinct types of user queries:

- **Dictionary/Keyword Questions:**  
  Simple requests for the definition of a financial term  
  *(e.g., â€œWhat is inflation?â€)*

- **General/Knowledge Questions:**  
  More complex, conversational queries that require a generated response  
  *(e.g., â€œHow can I start investing in stocks?â€)*

To achieve this, the chatbot uses a **two-stage hybrid model**:

1. **Intent Classifier (Bidirectional LSTM):**  
   Classifies the user's input to determine if it's a *dictionary* question or a *general* question.

2. **Response Generator (Sequence-to-Sequence):**  
   Based on the classification, the system either retrieves a predefined definition or uses a generative Seq2Seq model to create a novel answer.

---

## âš™ï¸ How It Works: Architecture

When a user inputs a question, it goes through the following pipeline:

### ğŸ§  1. Classification
- The input is tokenized using the **`lstm_tokenizer`**.
- It's fed into the **`bidirectional_LSTM.h5`** model, which outputs a score.

### ğŸ”€ 2. Branching Logic

#### If **score > 0.5** â†’ *Dictionary Query*
- The system identifies the query as a request for a definition.  
- It searches the **`keyword_dict.pkl`** for a matching financial term.  
- It returns the predefined definition associated with that term.

#### If **score â‰¤ 0.5** â†’ *Generative Query*
- The system identifies the query as a general, knowledge-based question.  
- The input is tokenized using the **`seq2seq_tokenizer`** (*Final_Tokenizer*).  
- It's processed by the **`chatbot.h5`** (*Sequence-to-Sequence*) model, which generates an answer token-by-token.  
- The final generated sentence is cleaned and returned to the user.

---

## ğŸ§© Project Structure



<img width="690" height="639" alt="image" src="https://github.com/user-attachments/assets/6f6d997b-b951-4718-968c-a2612de2d256" />



*(Insert architecture image below)*  
![Architecture Diagram](image)

---

## ğŸ› ï¸ Technologies Used

- **Python 3**
- **TensorFlow & Keras** â€” For building and serving both the LSTM and Seq2Seq models.  
- **TensorFlow Datasets** â€” For `SubwordTextEncoder` tokenization.  
- **NumPy** â€” For numerical operations and sequence padding.  
- **Pickle** â€” For loading the keyword dictionary.

---
